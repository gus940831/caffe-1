{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: cp949 -*-\n",
    "# -*- coding: utf-8 -*- # 한글 주석쓰려면 이거 해야함\n",
    "\n",
    "import cv2 # opencv 사용\n",
    "image = cv2.imread('/home/socmgr/solidWhiteCurve.jpg') # 이미지 읽기\n",
    "\n",
    "cv2.imshow('result',image) # 이미지 출력 cv2.waitKey(0)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: cp949 -*-\n",
    "# -*- coding: utf-8 -*- # 한글 주석쓰려면 이거 해야함\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('/home/socmgr/solidWhiteCurve.jpg') # 이미지 읽기\n",
    "mark = np.copy(image) #image 복사\n",
    "\n",
    "blue_threshold = 200\n",
    "green_threshold = 200\n",
    "red_threshold = 200\n",
    "bgr_threshold = [blue_threshold, green_threshold, red_threshold]\n",
    "\n",
    "threshold = (image[:,:,0] < bgr_threshold[0]) \\\n",
    "            | (image[:,:,1] < bgr_threshold[1])\\\n",
    "            | (image[:,:,2] < bgr_threshold[2])\n",
    "mark[threshold] = [0,0,0]\n",
    "\n",
    "cv2.imshow('white', mark)\n",
    "cv2.imshow('result', image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: cp949 -*-\n",
    "# -*- coding: utf-8 -*- # 한글 주석쓰려면 이거 해야함\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def region_of_interest(img, vertices, color3=(255,255,255), color1=255):\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    if len(img.shape) > 2:\n",
    "        color = color3\n",
    "    else:\n",
    "        color = color1\n",
    "        \n",
    "    cv2.fillPoly(mask, vertices, color)\n",
    "    ROI_image = cv2.bitwise_and(img, mask)\n",
    "    return ROI_image\n",
    "\n",
    "def mark_img(img, blue_threshold=200, green_threshold = 200, red_threshold = 200):\n",
    "    \n",
    "    bgr_threshold = [blue_threshold, green_threshold, red_threshold]\n",
    "    \n",
    "    threshold = (image[:,:,0] < bgr_threshold[0]) \\\n",
    "                | (image[:,:,1] < bgr_threshold[1])\\\n",
    "                | (image[:,:,2] < bgr_threshold[2])\n",
    "    mark[threshold] = [0,0,0]\n",
    "    return mark\n",
    "\n",
    "image = cv2.imread('/home/socmgr/solidWhiteCurve.jpg') # 이미지 읽기\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "vertices = np.array([[(50,height), (width/2-45, height/2+60), (width/2+45, height/2+60), (width-50,height)]], dtype=np.int32)\n",
    "roi_img = region_of_interest(image, vertices)\n",
    "\n",
    "mark = np.copy(roi_img)\n",
    "mark = mark_img(roi_img)\n",
    "\n",
    "cv2.imshow('roi_white', mark)\n",
    "cv2.imshow('result', image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: cp949 -*-\n",
    "# -*- coding: utf-8 -*- # 한글 주석쓰려면 이거 해야함\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def region_of_interest(img, vertices, color3=(255,255,255), color1=255):\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    if len(img.shape) > 2:\n",
    "        color = color3\n",
    "    else:\n",
    "        color = color1\n",
    "        \n",
    "    cv2.fillPoly(mask, vertices, color)\n",
    "    ROI_image = cv2.bitwise_and(img, mask)\n",
    "    return ROI_image\n",
    "\n",
    "def mark_img(img, blue_threshold=200, green_threshold = 200, red_threshold = 200):\n",
    "    \n",
    "    bgr_threshold = [blue_threshold, green_threshold, red_threshold]\n",
    "    \n",
    "    threshold = (image[:,:,0] < bgr_threshold[0]) \\\n",
    "                | (image[:,:,1] < bgr_threshold[1])\\\n",
    "                | (image[:,:,2] < bgr_threshold[2])\n",
    "    mark[threshold] = [0,0,0]\n",
    "    return mark\n",
    "\n",
    "image = cv2.imread('/home/socmgr/solidWhiteCurve.jpg') # 이미지 읽기\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "vertices = np.array([[(50,height), (width/2-45, height/2+60), (width/2+45, height/2+60), (width-50,height)]], dtype=np.int32)\n",
    "roi_img = region_of_interest(image, vertices, (0,255,0))\n",
    "#roi_img2 = region_of_interest(image, vertices, (0,255,0))\n",
    "#roi_img3 = region_of_interest(image, vertices, (0,0,255))\n",
    "\n",
    "mark = np.copy(roi_img)\n",
    "#mark2 = np.copy(roi_img2)\n",
    "#mark3 = np.copy(roi_img3)\n",
    "\n",
    "mark = mark_img(roi_img)\n",
    "#mark2 = mark_img(roi_img2)\n",
    "#mark3 = mark_img(roi_img3)\n",
    "\n",
    "cv2.imshow('roi_color', mark)\n",
    "#cv2.imshow('roi_green', mark2)\n",
    "#cv2.imshow('roi_red', mark3)\n",
    "cv2.imshow('result', image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: cp949 -*-\n",
    "# -*- coding: utf-8 -*- # 한글 주석쓰려면 이거 해야함\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def region_of_interest(img, vertices, color3=(255,255,255), color1=255):\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    if len(img.shape) > 2:\n",
    "        color = color3\n",
    "    else:\n",
    "        color = color1\n",
    "        \n",
    "    cv2.fillPoly(mask, vertices, color)\n",
    "    ROI_image = cv2.bitwise_and(img, mask)\n",
    "    return ROI_image\n",
    "\n",
    "def mark_img(img, blue_threshold=200, green_threshold = 200, red_threshold = 200):\n",
    "    \n",
    "    bgr_threshold = [blue_threshold, green_threshold, red_threshold]\n",
    "    \n",
    "    threshold = (image[:,:,0] < bgr_threshold[0]) \\\n",
    "                | (image[:,:,1] < bgr_threshold[1])\\\n",
    "                | (image[:,:,2] < bgr_threshold[2])\n",
    "    mark[threshold] = [0,0,0]\n",
    "    return mark\n",
    "\n",
    "image = cv2.imread('/home/socmgr/solidWhiteCurve.jpg') # 이미지 읽기\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "vertices = np.array([[(50,height), (width/2-45, height/2+60), (width/2+45, height/2+60), (width-50,height)]], dtype=np.int32)\n",
    "roi_img = region_of_interest(image, vertices, (0,255,0))\n",
    "#roi_img2 = region_of_interest(image, vertices, (0,255,0))\n",
    "#roi_img3 = region_of_interest(image, vertices, (0,0,255))\n",
    "\n",
    "mark = np.copy(roi_img)\n",
    "#mark2 = np.copy(roi_img2)\n",
    "#mark3 = np.copy(roi_img3)\n",
    "\n",
    "mark = mark_img(roi_img)\n",
    "#mark2 = mark_img(roi_img2)\n",
    "#mark3 = mark_img(roi_img3)\n",
    "\n",
    "color_thresholds = (mark[:,:,0] == 0) & (mark[:,:,1] > 200) & (mark[:,:,2] == 0)\n",
    "image[color_thresholds] = [0,255,0]\n",
    "\n",
    "cv2.imshow('roi_white', mark)\n",
    "#cv2.imshow('roi_green', mark2)\n",
    "#cv2.imshow('roi_red', mark3)\n",
    "cv2.imshow('result', image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-7acd8ae0b497>, line 56)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-7acd8ae0b497>\"\u001b[0;36m, line \u001b[0;32m56\u001b[0m\n\u001b[0;31m    cv2.destroyAllWindows()1\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#도로에 빨간 선 인식 코드\n",
    "# -*- coding: cp949 -*-\n",
    "# -*- coding: utf-8 -*- # 한글 주석쓰려면 이거 해야함\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def region_of_interest(img, vertices, color3=(255,255,255), color1=255):\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    if len(img.shape) > 2:\n",
    "        color = color3\n",
    "    else:\n",
    "        color = color1\n",
    "        \n",
    "    cv2.fillPoly(mask, vertices, color)\n",
    "    ROI_image = cv2.bitwise_and(img, mask)\n",
    "    return ROI_image\n",
    "\n",
    "def mark_img(img, blue_threshold=200, green_threshold = 200, red_threshold = 200):\n",
    "    \n",
    "    bgr_threshold = [blue_threshold, green_threshold, red_threshold]\n",
    "    \n",
    "    threshold = (image[:,:,0] < bgr_threshold[0]) \\\n",
    "                | (image[:,:,1] < bgr_threshold[1])\\\n",
    "                | (image[:,:,2] < bgr_threshold[2])\n",
    "    mark[threshold] = [0,0,0]\n",
    "    return mark\n",
    "\n",
    "cap = cv2.VideoCapture('/home/socmgr/drive.mp4') # 동영상 불러오기\n",
    "while(cap.isOpened()):\n",
    "    ret, image = cap.read()\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    #image = cv2.imread('/home/socmgr/drive.mp4') # 영상 읽기\n",
    "    #height, width = image.shape[:2]\n",
    "    vertices = np.array([[(50,height),(width/2-45, height/2+60), (width/2+45, height/2+60), (width-50,height)]], dtype=np.int32)\n",
    "    roi_img = region_of_interest(image, vertices, (0,0,255))\n",
    "    #roi_img2 = region_of_interest(image, vertices, (0,255,0))\n",
    "    #roi_img3 = region_of_interest(image, vertices, (0,0,255))\n",
    "\n",
    "    mark = np.copy(roi_img)\n",
    "    #mark2 = np.copy(roi_img2)\n",
    "    #mark3 = np.copy(roi_img3)\n",
    "\n",
    "    mark = mark_img(roi_img)\n",
    "    #mark2 = mark_img(roi_img2)\n",
    "    #mark3 = mark_img(roi_img3)\n",
    "\n",
    "    color_thresholds = (mark[:,:,0] == 0) & (mark[:,:,1] == 0) & (mark[:,:,2] > 200)\n",
    "    image[color_thresholds] = [0,0,255]\n",
    "\n",
    "    cv2.imshow('results', image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#도로에 빨간 선 인식 코드\n",
    "# -*- coding: cp949 -*-\n",
    "# -*- coding: utf-8 -*- # 한글 주석쓰려면 이거 해야함\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def region_of_interest(img, vertices, color3=(255,255,255), color1=255):\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    if len(img.shape) > 2:\n",
    "        color = color3\n",
    "    else:\n",
    "        color = color1\n",
    "        \n",
    "    cv2.fillPoly(mask, vertices, color)\n",
    "    ROI_image = cv2.bitwise_and(img, mask)\n",
    "    return ROI_image\n",
    "\n",
    "def mark_img(img, blue_threshold=200, green_threshold = 200, red_threshold = 200):\n",
    "    \n",
    "    bgr_threshold = [blue_threshold, green_threshold, red_threshold]\n",
    "    \n",
    "    threshold = (image[:,:,0] < bgr_threshold[0]) \\\n",
    "                | (image[:,:,1] < bgr_threshold[1])\\\n",
    "                | (image[:,:,2] < bgr_threshold[2])\n",
    "    mark[threshold] = [0,0,0]\n",
    "    return mark\n",
    "\n",
    "cap = cv2.VideoCapture('/home/socmgr/drive.mp4') # 동영상 불러오기\n",
    "while(cap.isOpened()):\n",
    "    ret, image = cap.read()\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    #image = cv2.imread('/home/socmgr/drive.mp4') # 영상 읽기\n",
    "    #height, width = image.shape[:2]\n",
    "    vertices = np.array([[(50,height),(width/2-45, height/2+60), (width/2+45, height/2+60), (width-50,height)]], dtype=np.int32)\n",
    "    roi_img = region_of_interest(image, vertices, (0,0,255))\n",
    "    #roi_img2 = region_of_interest(image, vertices, (0,255,0))\n",
    "    #roi_img3 = region_of_interest(image, vertices, (0,0,255))\n",
    "\n",
    "    mark = np.copy(roi_img)\n",
    "    #mark2 = np.copy(roi_img2)\n",
    "    #mark3 = np.copy(roi_img3)\n",
    "\n",
    "    mark = mark_img(roi_img)\n",
    "    #mark2 = mark_img(roi_img2)\n",
    "    #mark3 = mark_img(roi_img3)\n",
    "\n",
    "    color_thresholds = (mark[:,:,0] == 0) & (mark[:,:,1] == 0) & (mark[:,:,2] > 200)\n",
    "    image[color_thresholds] = [0,0,255]\n",
    "\n",
    "    cv2.imshow('results', image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Canny 알고리즘/가우시안 함수 사용\n",
    "# -*- coding: cp949 -*-\n",
    "# -*- coding: utf-8 -*- # 한글 주석쓰려면 이거 해야함\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def grayscale(img):  #흑백 이미지로 변환\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):   #Canny 알고리즘\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size): #가우시안 필터\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "\n",
    "image = cv2.imread('/home/socmgr/solidWhiteCurve.jpg') #이미지 읽기\n",
    "height, width = image.shape[:2] # 이미지 높이, 너비\n",
    "\n",
    "gray_img = grayscale(image) #흑백이미지로 변환\n",
    "\n",
    "blur_img = gaussian_blur(gray_img, 3) # blur 효과\n",
    "\n",
    "canny_img = canny(blur_img, 70, 210) #canny edge 알고리즘\n",
    "\n",
    "cv2.imshow('result', canny_img) # canny 이미지 출력\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Canny 알고리즘/가우시안 함수/HoughLinesP()함수/ addWeighted()함수 사\n",
    "# -*- coding: cp949 -*-\n",
    "# -*- coding: utf-8 -*- # 한글 주석쓰려면 이거 해야함\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def grayscale(img):  #흑백 이미지로 변환\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):   #Canny 알고리즘\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size): #가우시안 필터\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices, color3 = (255,255,255), color1 = 255): #ROI 셋팅\n",
    "    mask = np.zeros_like(img) #mask = img와 같은 크기의 빈 이미지\n",
    "    \n",
    "    if len(img.shape) > 2: #Color 이미지 (3채널)이라면 :\n",
    "        color = color3\n",
    "    else: #흑백 이미지(1채널)이라면 :\n",
    "        color = color1\n",
    "    # vertices에 정한 점들로 이뤄진 다각형부분(ROI 설정부분)을 color로 채움\n",
    "    cv2.fillPoly(mask, vertices, color)\n",
    "     # 이미지와 color로 채워진 ROI를 합침\n",
    "    ROI_image = cv2.bitwise_and(img, mask)\n",
    "    return ROI_image\n",
    "\n",
    "def draw_lines(img, lines, color=[0, 0, 255], thickness=2): #선 그리기\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "            \n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap): #허프변환 \n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "\n",
    "    return line_img\n",
    "\n",
    "def weighted_img(img, initial_img, α=1, β=1., λ=0.): # 두 이미지 operlap 하기\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "    \n",
    "image = cv2.imread('/home/socmgr/solidWhiteCurve.jpg') #이미지 읽기\n",
    "height, width = image.shape[:2] # 이미지 높이, 너비\n",
    "\n",
    "gray_img = grayscale(image) #흑백이미지로 변환\n",
    "\n",
    "blur_img = gaussian_blur(gray_img, 3) # blur 효과\n",
    "\n",
    "canny_img = canny(blur_img, 70, 210) #canny edge 알고리즘\n",
    "\n",
    "vertices = np.array([[(50,height),(width/2-45, height/2+60), (width/2+45, height/2+60), (width-50,height)]], dtype=np.int32)\n",
    "ROI_img = region_of_interest(canny_img, vertices) #ROI 설정\n",
    "    \n",
    "hough_img = hough_lines(ROI_img, 1, 1 * np.pi/180, 30, 10, 20) #허프 변환\n",
    "\n",
    "result = weighted_img(hough_img, image) #원본 이미지에 검출된 선 overlap\n",
    "\n",
    "cv2.imshow('result', result) # 결과 이미지 출력\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-010ee9cc1afa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mROI_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregion_of_interest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanny_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#ROI 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mhough_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhough_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROI_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#허프 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhough_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#원본 이미지에 검출된 선 overlap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-010ee9cc1afa>\u001b[0m in \u001b[0;36mhough_lines\u001b[0;34m(img, rho, theta, threshold, min_line_len, max_line_gap)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHoughLinesP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminLineLength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_line_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxLineGap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_line_gap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mline_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mdraw_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mline_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-010ee9cc1afa>\u001b[0m in \u001b[0;36mdraw_lines\u001b[0;34m(img, lines, color, thickness)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdraw_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthickness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#선 그리기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthickness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "#Canny 알고리즘/가우시안 함수/HoughLinesP()함수/ addWeighted()함수 사\n",
    "# -*- coding: cp949 -*-\n",
    "# -*- coding: utf-8 -*- # 한글 주석쓰려면 이거 해야함\n",
    "# 동영상\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def grayscale(img):  #흑백 이미지로 변환\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):   #Canny 알고리즘\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size): #가우시안 필터\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices, color3 = (255,255,255), color1 = 255): #ROI 셋팅\n",
    "    mask = np.zeros_like(img) #mask = img와 같은 크기의 빈 이미지\n",
    "    \n",
    "    if len(img.shape) > 2: #Color 이미지 (3채널)이라면 :\n",
    "        color = color3\n",
    "    else: #흑백 이미지(1채널)이라면 :\n",
    "        color = color1\n",
    "    # vertices에 정한 점들로 이뤄진 다각형부분(ROI 설정부분)을 color로 채움\n",
    "    cv2.fillPoly(mask, vertices, color)\n",
    "     # 이미지와 color로 채워진 ROI를 합침\n",
    "    ROI_image = cv2.bitwise_and(img, mask)\n",
    "    return ROI_image\n",
    "\n",
    "def draw_lines(img, lines, color=[0, 0, 255], thickness=2): #선 그리기\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "            \n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap): #허프변환 \n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "\n",
    "    return line_img\n",
    "\n",
    "def weighted_img(img, initial_img, α=1, β=1., λ=0.): # 두 이미지 operlap 하기\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "cap = cv2.VideoCapture('/home/socmgr/drive.mp4') # 동영상 불러오기\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, image = cap.read()\n",
    "    \n",
    "    height, width = image.shape[:2] #이미지 높이, 너비\n",
    "    \n",
    "    #image = cv2.imread('/home/socmgr/solidWhiteCurve.jpg') #이미지 읽기\n",
    "    #height, width = image.shape[:2] # 이미지 높이, 너비\n",
    "\n",
    "    gray_img = grayscale(image) #흑백이미지로 변환\n",
    "\n",
    "    blur_img = gaussian_blur(gray_img, 3) # blur 효과\n",
    "\n",
    "    canny_img = canny(blur_img, 70, 210) #canny edge 알고리즘\n",
    "\n",
    "    vertices = np.array([[(50,height),(width/2-45, height/2+60), (width/2+45, height/2+60), (width-50,height)]], dtype=np.int32)\n",
    "    ROI_img = region_of_interest(canny_img, vertices) #ROI 설정\n",
    "    \n",
    "    hough_img = hough_lines(ROI_img, 1, 1 * np.pi/180, 30, 10, 20) #허프 변환\n",
    "\n",
    "    result = weighted_img(hough_img, image) #원본 이미지에 검출된 선 overlap\n",
    "    cv2.imshow('result', result) # 결과 이미지 출력\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
